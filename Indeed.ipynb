{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Data Scraping Project\n",
    "The goal of this project is to automate Indeed Job searching by allowing the user to input a state of their choice and returning a CSV with the job listings in the first 10 pages on Indeed. This will the job searching process much easier for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first start by attempting to create a dataframe from just one Indeed page URL. Note this is a sample URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.indeed.com/q-Data-Scientist-l-San-Francisco,-CA-jobs.html?vjk=bc7c0e642f6453f4\"\n",
    "request = requests.get(URL)\n",
    "print(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Awesome, we got a response code 200 meaning our request was successful! Let's now view the page as HTML and use BeautifulSoup to make it look nicer. I will comment out the print statement so it won't display the whole html because it is very long :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_html = BSoup(request.text, \"html.parser\")\n",
    "#print(page_html.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "containers = page_html.findAll(name=\"div\", attrs={\"class\": \"row\"})\n",
    "len(containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks like there are 15 job from this sample URL. Let's now try to extract the job title from each listing by looking at the HTML tags from the page_html variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Associate Data Scientist I',\n",
       " 'Data Scientist',\n",
       " 'Research Data Scientist',\n",
       " 'Data Scientist: Data Visualization',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / Quantitative Research',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist, Machine Learning innovator',\n",
       " 'Data Scientist â€“ Experimentation (Contract Position)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for container in containers:\n",
    "        for a in container.find_all(name=\"a\", attrs={\"data-tn-element\": \"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return jobs\n",
    "\n",
    "extract_job_title_from_result(page_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do the same for the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Triplebyte',\n",
       " 'Global Fishing Watch',\n",
       " 'Blue Owl',\n",
       " 'Levi Strauss & Co.',\n",
       " 'project AI',\n",
       " 'University of California San Francisco',\n",
       " 'Kaiser Permanente',\n",
       " 'Common Networks',\n",
       " 'Yelp',\n",
       " 'Applied Technology & Science (A-T-S)',\n",
       " 'GradTests (gradtests.com)',\n",
       " 'PicnicHealth',\n",
       " 'Deep Labs',\n",
       " 'Standard Chartered',\n",
       " 'Getty Images']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company_from_result(soup): \n",
    "    companies = []\n",
    "    for container in containers:\n",
    "        company = container.find_all(name=\"span\", attrs={\"class\": \"company\"})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            test2 = div.find_all(name=\"span\", attrs={\"class\": \"result-link-source\"})\n",
    "            for span in test2:\n",
    "                companies.append(span.text.strip())\n",
    "    return(companies)\n",
    " \n",
    "extract_company_from_result(page_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do the same for the salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$145,000 - $225,000 a year',\n",
       " '$45 - $65 an hour',\n",
       " '$250,000 - $375,000 a year',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " '$120,000 a year',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " 'Not Available']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_salary_from_result(soup): \n",
    "    salaries = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\": \"row\"}):\n",
    "        div_two = div.find(name=\"span\", attrs={'class': \"salaryText\"})\n",
    "        if div_two == None:\n",
    "            salaries.append(\"Not Available\")\n",
    "        else:\n",
    "            salaries.append(div_two.text.strip())\n",
    "    return salaries \n",
    "\n",
    "extract_salary_from_result(page_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And finally, let's do the same for ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.0',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " '3.9',\n",
       " 'Not Available',\n",
       " '4.2',\n",
       " '4.1',\n",
       " 'Not Available',\n",
       " '3.5',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " '3.7',\n",
       " '4.1',\n",
       " '3.9']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_ratings_from_result(soup): \n",
    "    ratings = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\": \"row\"}):\n",
    "        div_two = div.find(name=\"span\", attrs={'class': \"ratingsContent\"})\n",
    "        if div_two == None:\n",
    "            ratings.append(\"Not Available\")\n",
    "        else:\n",
    "            ratings.append(div_two.text.strip())\n",
    "    return ratings\n",
    "\n",
    "extract_ratings_from_result(page_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's build a dataframe by combining all the information we have so far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Triplebyte</td>\n",
       "      <td>$145,000 - $225,000 a year</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Global Fishing Watch</td>\n",
       "      <td>$45 - $65 an hour</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Blue Owl</td>\n",
       "      <td>$250,000 - $375,000 a year</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Data Scientist I</td>\n",
       "      <td>Levi Strauss &amp; Co.</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>project AI</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Research Data Scientist</td>\n",
       "      <td>University of California San Francisco</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist: Data Visualization</td>\n",
       "      <td>Kaiser Permanente</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Common Networks</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Technology &amp; Science (A-T-S)</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GradTests (gradtests.com)</td>\n",
       "      <td>$120,000 a year</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist / Quantitative Research</td>\n",
       "      <td>PicnicHealth</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Deep Labs</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist, Machine Learning innovator</td>\n",
       "      <td>Standard Chartered</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist â€“ Experimentation (Contract Pos...</td>\n",
       "      <td>Getty Images</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "0                                      Data Scientist   \n",
       "1                                      Data Scientist   \n",
       "2                                      Data Scientist   \n",
       "3                          Associate Data Scientist I   \n",
       "4                                      Data Scientist   \n",
       "5                             Research Data Scientist   \n",
       "6                  Data Scientist: Data Visualization   \n",
       "7                                      Data Scientist   \n",
       "8                                      Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "11             Data Scientist / Quantitative Research   \n",
       "12                                     Data Scientist   \n",
       "13         Data Scientist, Machine Learning innovator   \n",
       "14  Data Scientist â€“ Experimentation (Contract Pos...   \n",
       "\n",
       "                                   company                      salary  \\\n",
       "0                               Triplebyte  $145,000 - $225,000 a year   \n",
       "1                     Global Fishing Watch           $45 - $65 an hour   \n",
       "2                                 Blue Owl  $250,000 - $375,000 a year   \n",
       "3                       Levi Strauss & Co.               Not Available   \n",
       "4                               project AI               Not Available   \n",
       "5   University of California San Francisco               Not Available   \n",
       "6                        Kaiser Permanente               Not Available   \n",
       "7                          Common Networks               Not Available   \n",
       "8                                     Yelp               Not Available   \n",
       "9     Applied Technology & Science (A-T-S)               Not Available   \n",
       "10               GradTests (gradtests.com)             $120,000 a year   \n",
       "11                            PicnicHealth               Not Available   \n",
       "12                               Deep Labs               Not Available   \n",
       "13                      Standard Chartered               Not Available   \n",
       "14                            Getty Images               Not Available   \n",
       "\n",
       "           rating  \n",
       "0             5.0  \n",
       "1   Not Available  \n",
       "2   Not Available  \n",
       "3             3.9  \n",
       "4   Not Available  \n",
       "5             4.2  \n",
       "6             4.1  \n",
       "7   Not Available  \n",
       "8             3.5  \n",
       "9   Not Available  \n",
       "10  Not Available  \n",
       "11  Not Available  \n",
       "12            3.7  \n",
       "13            4.1  \n",
       "14            3.9  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = pd.DataFrame({\"job_title\": extract_job_title_from_result(page_html), \n",
    "                         \"company\": extract_company_from_result(page_html),\n",
    "                         \"salary\": extract_salary_from_result(page_html),\n",
    "                         \"rating\": extract_ratings_from_result(page_html)}) \n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! It looks good except that we need to clean the salary series since it is not consistent with units (years and hour). We won't worry too much about that right now. Let's now try to get all listings from the first 10 pages of the Indeed searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 100\n",
    "columns = [\"job_title\", \"company\", \"salary\", \"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Francisco\n"
     ]
    }
   ],
   "source": [
    "a = input() # We want the user to be able to input a city of their choice, so we will test it using the input method\n",
    "city_selection = [a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a df\n",
    "sample_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "#loops through the 10 url for the selected city and gets the information\n",
    "for city in city_selection:\n",
    "    for start in range(0, limit, 10):\n",
    "        page = requests.get(\"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=\" + str(city) + \"&start=\" + str(start))\n",
    "        soup = BSoup(page.text, \"lxml\", from_encoding=\"utf-8\")\n",
    "        \n",
    "        for div in soup.find_all(name=\"div\", attrs={\"class\": \"row\"}): \n",
    "            num = (len(sample_df) + 1) \n",
    "            job_post = [] \n",
    "            \n",
    "            for a in div.find_all(name=\"a\", attrs={\"data-tn-element\": \"jobTitle\"}):\n",
    "                job_post.append(a[\"title\"])\n",
    "            company = div.find_all(name=\"span\", attrs={\"class\": \"company\"}) \n",
    "            if len(company) > 0: \n",
    "                for b in company:\n",
    "                    job_post.append(b.text.strip()) \n",
    "            else: \n",
    "                test2 = div.find_all(name=\"span\", attrs={\"class\": \"result-link-source\"})\n",
    "                for span in test2:\n",
    "                    job_post.append(span.text)\n",
    "                    \n",
    "            div_two = div.find(name=\"span\", attrs={\"class\": \"salaryText\"})\n",
    "            if div_two == None:\n",
    "                job_post.append(\"Not Available\")\n",
    "            else:\n",
    "                job_post.append(div_two.text.strip())\n",
    "                \n",
    "            div_three = div.find(name=\"span\", attrs={\"class\": \"ratingsContent\"})\n",
    "            if div_three == None:\n",
    "                job_post.append(\"Not Available\")\n",
    "            else:\n",
    "                job_post.append(div_three.text.strip())\n",
    "            \n",
    "            sample_df.loc[num] = job_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we are going to clean this data and then convert the dataframe into a CSV file. Let's start by cleaning the salary series to the correct rates. We will convert them into dollars a year. \n",
    "\n",
    "##### Note: the string manipulation below assumes that hourly salaries are two digits and monthly to be in the thousands since salaries for these jobs. We can safely make this assumption for now as annual income for this position is usually 50k-200k which supports that range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the salary series\n",
    "result = sample_df[\"salary\"]\n",
    "\n",
    "# Checking units, converting, and formatting them appropriately\n",
    "for index, item in enumerate(sample_df[\"salary\"]):\n",
    "    if \"hour\" in item and '-' in item:\n",
    "        lower = int(item[1:3])*8*365\n",
    "        upper = int(item[7:9])*8*365\n",
    "        result[index + 1] = \"$\" + \"{:,}\".format(lower) + \" - \" + \"$\" + \"{:,}\".format(upper) + \" a year\"\n",
    "    elif \"hour\" in item and '-' not in item:\n",
    "        salary = int(item[1:3])*8*365\n",
    "        result[index + 1] = \"$\" + \"{:,}\".format(salary) + \" a year\"\n",
    "    elif 'month' in item:\n",
    "        no_range = int(item[1:2] + item[3:6])*12\n",
    "        result[index + 1] = \"$\" + \"{:,}\".format(no_range) + \" a year\"\n",
    "    else:\n",
    "        result[index + 1] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Awesome, it looks like it worked properly. For example, in our old series for index 134, it was 5,000 monthly which converts to 60,000 a year in our results series. Let's now finish off by printing our whole dataframe out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks good! Let's now finally convert this Pandas dataframe into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('indeed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
